<!DOCTYPE html>
<html>
	<head>
		<title>What - Tarpeeksi Hyvae Soft</title>
        <meta http-equiv="content-type"
              content="text/html; charset=UTF-8">
        <meta name="viewport"
              content="width=device-width">
        <link rel="stylesheet"
              href="https://use.fontawesome.com/releases/v5.6.1/css/all.css"
              integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP"
              crossorigin="anonymous">
        <link rel="stylesheet"
              type="text/css"
              href="index.css">
	</head>
	<body>
        <div id="app">

            <input v-visible-if="!isVideoPlaying"
                   type="file"
                   id="video-file-selector"
                   accept="video/*">

            <video v-cloak
                   v-visible-if="isVideoPlaying"
                   id="video-player"></video>

            <div v-cloak
                 v-visible-if="isVideoPlaying"
                 id="bar-container">
                <div id="canvas-container">
                    <canvas id="test-canvas" width="600" height="100"></canvas>
                </div>
            </div>

            <div v-cloak
                 v-visible-if="isVideoPlaying && !isVideoProcessingFinished"
                 class="message">
                Processing
            </div>

        </div>

        <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>

        <script>
            Vue.directive("visible-if", (el, binding)=>
            {
                el.style.visibility = (binding.value? "visible" : "hidden");
            });

            const ui = new Vue({
                el: "#app",
                data: {
                    isVideoPlaying: false,
                    isVideoProcessingFinished: false,
                }
            });

            const renderWidth = document.getElementById("test-canvas").width;
            const renderHeight = document.getElementById("test-canvas").height;
            const renderContext = document.getElementById("test-canvas").getContext("2d");
            const canvasImage = renderContext.getImageData(0, 0, renderWidth, renderHeight);
            let percentCompleted = 0;

            function set_spectrogram_value(x, y, value)
            {
                y = (renderHeight - y - 1);

                const idx = ((x + y * renderWidth) * 4);
                canvasImage.data[idx+3] = value;
            }

            function get_spectrogram_value(x, y)
            {
                y = (renderHeight - y - 1);

                const idx = ((x + y * renderWidth) * 4);
                return canvasImage.data[idx+3];
            }

            for (let y = 0; y < renderHeight; y++)
            {
                for (let x = 0; x < renderWidth; x++)
                {
                    const idx = ((x + y * renderWidth) * 4);
                    canvasImage.data[idx+0] = 0;
                    canvasImage.data[idx+1] = 0;
                    canvasImage.data[idx+2] = 0;
                    canvasImage.data[idx+3] = 0;
                }
            }

            setInterval(()=>
            {
                document.getElementById("canvas-container").style.width = `${Math.min(96, percentCompleted * 96)}vw`;
                renderContext.putImageData(canvasImage, 0, 0);

                /// TODO: Stop this interval after video processing is done.
            }, 1000);

			document.getElementById("video-file-selector").onchange = async function()
			{
				const videoFile = this.files[0];
                const player = document.getElementById("video-player");
                const audioContext = new AudioContext();

                player.src = URL.createObjectURL(videoFile);
                player.playbackRate = 16;
                player.onplay = ()=>
                {
                    ui.isVideoPlaying = true;
                }
                player.onended = ()=>
                {
                    ui.isVideoProcessingFinished = true;
                    percentCompleted = 1;
                }

                const audioSource = audioContext.createMediaElementSource(player);
                const audioAnalyzer = audioContext.createAnalyser();
                audioSource.connect(audioAnalyzer);
                audioAnalyzer.connect(audioContext.destination);

                player.play();

                // Sample the audio buffer every x milliseconds.
                setInterval(()=>
                {
                    const spectrum = new Uint8Array(audioAnalyzer.frequencyBinCount);
                    audioAnalyzer.getByteFrequencyData(spectrum);

                    percentCompleted = ((player.currentTime / player.duration) || 0);

                    for (let y = 0; y < renderHeight; y++)
                    {
                        const sampleIdx = Math.floor(y * ((audioAnalyzer.frequencyBinCount / 8) / renderHeight));
                        const amplitude = Math.min(255, (spectrum[sampleIdx] * 3));
                        const x = Math.floor(renderWidth * percentCompleted);

                        if (get_spectrogram_value(x, y) < amplitude)
                        {
                            set_spectrogram_value(x, y, amplitude);
                        }
                    }
                }, 10);
            };
        </script>
    </body>
</html>

